# H200 production environment with GPU-accelerated TEI (Text Embeddings Inference)
# Usage: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
#
# Requires NVIDIA Container Toolkit. TEI runs on GPU 0.
# Jina Code V2 requires --trust-remote-code (GPU backend only).
# Pre-download models with: make download-model

services:
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:hopper-1.8
    container_name: tei
    ports:
      - "8090:80"
    volumes:
      - ./data/models:/data
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
    command: >
      --model-id jinaai/jina-embeddings-v2-base-code
      --trust-remote-code
      --port 80
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 15s
      timeout: 10s
      retries: 40
      start_period: 30s
    restart: unless-stopped

  lightrag:
    image: lightrag:local
    depends_on:
      tei:
        condition: service_healthy
    environment:
      - EMBEDDING_BINDING=openai
      - EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code
      - EMBEDDING_DIM=768
      - EMBEDDING_SEND_DIM=false
      - EMBEDDING_TOKEN_LIMIT=8192
      - EMBEDDING_BINDING_HOST=http://tei:80/v1
      - EMBEDDING_BINDING_API_KEY=dummy
